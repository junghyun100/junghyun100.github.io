---
layout: post
title: "네트워크 - Cookies and Web Caching"
tags: [컴퓨터 네트워크]
comments: true

---

컴퓨터 네트워크를 공부하면서 정리를 한 내용들 입니다.

-참고 K-mooc 부산 대학교 유영환 교수님 : 컴퓨터 네트워크 강의

---

# Cookie

인터넷 쇼핑몰 등을 접속하다 보면 내가 접속만 하면 자동으로 로그인 되는 경우가 있습니다.

아직 로그인을 하지 않았는데도 쇼핑 카트에 담아 두었던 데이터가 

접속 하자마자 쇼핑 카트에 그대로 남아 있는 것을 볼 수 있습니다.

그런데 HTTP의 특성과 비교를 해 보면 조금 이해가 안가는 점이 있습니다.

왜냐하면 <strong>HTTP는 stateless</strong>한 성질을 가지기 때문입니다. 

클라이언트의 상태를 저장 하지 않는다는 것 입니다.

HTTP는 기본적으로 이런 것이 되지 않기 때문에 

그것을 제공 하기 위해서 쿠키(Cookies)라는 것을 새롭게 개발했습니다.

HTTP가 제공하지 않는 사용자 state를 쿠키를 통해서 서버에 저장 해 두겠다는 것 입니다.

### Cookies : Keeping "State"

<img src="https://raw.githubusercontent.com/junghyun100/junghyun100.github.io/master/images/1115/%EC%BF%A0%ED%82%A4.PNG">

클라이언트가 아마존 서버에 접속을 하는 상황이라고 생각을 해 봅시다.

클라이언트는 HTTP request message를 가지고 아마존 서버에 접속을 시도 합니다.

접속을 하면 아마존 서버는 새로이 접속한 이 유저에 대해서 어떤 ID를 만듭니다. 

자동으로 ID로 만드는 것이죠.

사용자가 만드는 것이 아니라 <strong>접속 하는 순간</strong> 이 서버가 자동으로 ID를 만들고 임의의 번호를 이 유저에게 할당 하는 것입니다.

예를 들면 1678이라는 번호를 할당하고 데이터베이스에 저장을 해 두는 것 입니다.

이렇게 만든 뒤에 response를 보낼 때 set-cookie 필드에다가 1678이라는 자기가 생성한 쿠키 아이디를 담아서 전송을 합니다.

브라우저가 set-cookie라는 명령을 발견하면 자신의 쿠키 파일에다가 이것을 저장 해 두는 것입니다.

다시 아마존 서버에 접속 할 때 브라우저는 자신의 쿠키 파일을 살펴 봅니다.

아마존에서 쿠키 아이디 1678을 받은 기록이 있기 때문에 request message를 보낼 때 쿠키 아이디를 같이 담아서 보냅니다.

그럼 아마존 서버에서는 사용자가 어떤 일들을 했는가, 쇼핑 카트에 무엇을 담아 두었는가에 대한 정보를 가져 와서 바로 보여줍니다.

### Cookies on Browsers

쿠키는 어떤 상태를 서버가 유지 하기 때문에, 어떻게 보면 프라이버시를 침해 할 수도 있습니다.

나는 사실 서버가 나에 대한 정보를 갖고 있는 것을 원치 않는데 가지고 있으니 프라이버시를 침해 할 수도 있는 것입니다.

그래서 경우에 따라서는 어떤 사람은 쿠키를 사용하고 싶지 않은 사람도 있습니다. 

그런 사람들을 위해 브라우저에서 쿠키를 삭제 할 수 있습니다.

이렇게 삭제를 하게 된다면 내가 접속을 할 때 쿠키 아이디를 서버 쪽에 전달 하지 않습니다.

이제 서버측에서는 내가 누군지를 알지 못한다는 것입니다.********

## Web Caching(Proxy Server)

<img src="https://raw.githubusercontent.com/junghyun100/junghyun100.github.io/master/images/1115/%EC%9B%B9%EC%BC%80%EC%8B%B1.PNG">

예를 들어 구글 또는 네이버나 다음 같은 사이트를 많은 사람들이 접속한다면, 

request와 response가 클라이언트와 서버 사이를 계속 왔다 갔다 하려면 오버헤드가 굉장히 큽니다.

그래서 이 기관에서 중간에 프록시 서버(proxy server)라는 것을 하나 둡니다.

어떤 사람이 먼저 특정 사이트에 접속하기 위해서 request message를 보냈다.

그러면 그것이 처음에는 원래 오리진 서버(origin server)에 갔다가 응답을 받아 올 것입니다.

받아온 정보를 그냥 클라이언트에 전달 해 주고 끝나는 것이 아니라 중간의 프록시 서버가 그것을 보관합니다.

다른 클라이언트가 또는 같은 클라이언트가 똑같은 사이트에 대한 정보를 요구한 request를 보내게 되면

오리진 서버에 보낼 필요 없이 프록시 서버가 바로 response를 해 줍니다.

결국은 프록시 서버는 

1. 첫 번째 request : 오리진 서버에 전달 해 주고 response를 받음으로써 클라이언트로 동작
2. 두 번째 request : 클라이언트에 대해서 서버로 동작

웹 캐싱을 하게 되면 좋은 점이 많이 있습니다. 

* 클라이언트 입장에서는 

    request가 굳이 진짜 서버에 까지 갔다 올 필요가 없기 때문에 응답 시간이 매우 짧아집니다.

* 서버 입장에서는 

    프록시 서버가 없다고 하면 매번 나에게 날아와야 될 request message가 중간에서 이 프록시 서버가 해결을 해 주니까<br>용량이 좀 작아도 서비스를 잘 할 수 있습니다.

    이 서버 입장에서는 같은 용량으로 더 많은 사용자에게 서비스를 할 수 있는 장점이 있습니다.

* 로컬 네트워크를 운영하는 입장에서 

    인터넷을 사용하게 되면 요즘 용량이 기가 인터넷급이라 충분하지만,<br>문제가 되는 것은 로컬 ISP에서 인터넷으로 연결되는 부분입니다.
    Request가 계속 한쪽으로 날아가고 response가 계속 날아오면 병목이 생길 수 있습니다. 그럼 전체적으로 인터넷 서비스가 품질이 낮아집니다.
    
    그런데 중간에 프록시 서버를 설치 해서 대부분의 request를 처리 하게 되면 외부 인터넷과 local area network를 연결 하는 이 링크의 용량이 줄어들고, 서비스가 좋아지는 장점이 있습니다.
    
    
---
